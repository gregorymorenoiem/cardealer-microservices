# ğŸ¤– Reemplazo de Spyne AI con Modelos Propios

**Ãšltima actualizaciÃ³n:** Enero 26, 2026  
**Autor:** Equipo OKLA  
**Estado:** ğŸ“‹ AnÃ¡lisis y Propuesta

---

## ğŸ“‹ Resumen Ejecutivo

Este documento analiza las funcionalidades de Spyne AI y propone modelos de IA open-source y comerciales para replicar cada capacidad internamente, eliminando la dependencia de Spyne.

---

## ğŸ¯ Funcionalidades de Spyne AI a Reemplazar

| #   | Funcionalidad                 | DescripciÃ³n                                  | Complejidad |
| --- | ----------------------------- | -------------------------------------------- | ----------- |
| 1   | **Background Replacement**    | Reemplazar fondo de fotos de vehÃ­culos       | ğŸŸ¡ Media    |
| 2   | **Vehicle Segmentation**      | Detectar y separar vehÃ­culo del fondo        | ğŸŸ¡ Media    |
| 3   | **Image Classification**      | Clasificar: Exterior/Interior/Misc           | ğŸŸ¢ Baja     |
| 4   | **Angle Detection**           | Detectar Ã¡ngulo: front/rear/side/quarter     | ğŸŸ¢ Baja     |
| 5   | **License Plate Masking**     | Enmascarar placas automÃ¡ticamente            | ğŸŸ¢ Baja     |
| 6   | **360Â° Spin Generation**      | Generar viewer 360Â° desde mÃºltiples imÃ¡genes | ğŸŸ¡ Media    |
| 7   | **Shadow Generation**         | Generar sombras realistas en nuevo fondo     | ğŸŸ¡ Media    |
| 8   | **Color/Exposure Correction** | Normalizar colores e iluminaciÃ³n             | ğŸŸ¢ Baja     |
| 9   | **Video Frame Extraction**    | Extraer frames de video para 360Â°            | ğŸŸ¢ Baja     |
| 10  | **Feature Video Generation**  | Generar video promocional                    | ğŸ”´ Alta     |

---

## ğŸ§  Modelos de IA Recomendados por Funcionalidad

### 1ï¸âƒ£ Background Replacement (SegmentaciÃ³n + Inpainting)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PIPELINE: BACKGROUND REPLACEMENT                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   ğŸ“· Imagen Original                                                        â”‚
â”‚         â”‚                                                                   â”‚
â”‚         â–¼                                                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                       â”‚
â”‚   â”‚ 1. SEGMENTACIÃ“N â”‚  â—„â”€â”€ SAM 2 (Segment Anything Model 2)                â”‚
â”‚   â”‚    del VehÃ­culo â”‚      Meta AI - Open Source                           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      https://github.com/facebookresearch/sam2        â”‚
â”‚            â”‚                                                                â”‚
â”‚            â–¼                                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                       â”‚
â”‚   â”‚ 2. MÃSCARA      â”‚  Resultado: MÃ¡scara binaria del vehÃ­culo             â”‚
â”‚   â”‚    Generada     â”‚  (vehicle = 1, background = 0)                       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                       â”‚
â”‚            â”‚                                                                â”‚
â”‚            â–¼                                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                       â”‚
â”‚   â”‚ 3. COMPOSICIÃ“N  â”‚  â—„â”€â”€ Simple alpha compositing                        â”‚
â”‚   â”‚    con Nuevo BG â”‚      OpenCV / Pillow                                 â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                       â”‚
â”‚            â”‚                                                                â”‚
â”‚            â–¼                                                                â”‚
â”‚   ğŸ¨ Imagen Final con Nuevo Fondo                                           â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Modelos Recomendados:

| Modelo                       | Tipo                  | Licencia   | GPU Requerida | Calidad    |
| ---------------------------- | --------------------- | ---------- | ------------- | ---------- |
| **SAM 2 (Meta)**             | SegmentaciÃ³n          | Apache 2.0 | 8GB VRAM      | â­â­â­â­â­ |
| **SegGPT**                   | SegmentaciÃ³n          | MIT        | 16GB VRAM     | â­â­â­â­   |
| **UÂ²-Net**                   | SegmentaciÃ³n (ligero) | Apache 2.0 | 4GB VRAM      | â­â­â­â­   |
| **rembg (basado en UÂ²-Net)** | Background Removal    | MIT        | 2GB VRAM      | â­â­â­â­   |
| **CarveKit**                 | Background Removal    | MIT        | 4GB VRAM      | â­â­â­â­   |

#### CÃ³digo de Ejemplo (SAM 2):

```python
from sam2 import SAM2
import cv2
import numpy as np

# Cargar modelo
sam = SAM2.from_pretrained("facebook/sam2-hiera-large")

# Cargar imagen
image = cv2.imread("vehicle.jpg")

# Detectar vehÃ­culo automÃ¡ticamente (auto-prompt)
masks = sam.generate_masks(image, object_type="vehicle")

# Aplicar mÃ¡scara
vehicle_mask = masks[0]  # Primera mÃ¡scara (vehÃ­culo principal)

# Cargar fondo de estudio
background = cv2.imread("studio_background.jpg")
background = cv2.resize(background, (image.shape[1], image.shape[0]))

# ComposiciÃ³n
result = np.where(vehicle_mask[:,:,None], image, background)

cv2.imwrite("processed.jpg", result)
```

---

### 2ï¸âƒ£ Vehicle Segmentation (DetecciÃ³n de VehÃ­culo)

#### Modelos Recomendados:

| Modelo                | EspecializaciÃ³n        | Licencia   | Performance    |
| --------------------- | ---------------------- | ---------- | -------------- |
| **YOLO v8/v9**        | DetecciÃ³n de objetos   | AGPL-3.0   | Muy rÃ¡pido     |
| **Detectron2 (Meta)** | Instance Segmentation  | Apache 2.0 | Alta precisiÃ³n |
| **SAM 2**             | SegmentaciÃ³n universal | Apache 2.0 | Mejor calidad  |
| **Grounding DINO**    | Zero-shot detection    | Apache 2.0 | Flexible       |

#### Pipeline Recomendado:

```python
# OpciÃ³n 1: YOLO + SAM (mÃ¡s rÃ¡pido)
from ultralytics import YOLO
from sam2 import SAM2

yolo = YOLO("yolov8x.pt")
sam = SAM2.from_pretrained("facebook/sam2-hiera-base")

# YOLO detecta bounding box del vehÃ­culo
results = yolo(image, classes=[2, 5, 7])  # car, bus, truck

# SAM genera mÃ¡scara precisa usando el bbox como prompt
bbox = results[0].boxes[0].xyxy
mask = sam.segment_with_box(image, bbox)
```

---

### 3ï¸âƒ£ Image Classification (Exterior/Interior/Misc)

#### Modelos Recomendados:

| Modelo                       | Tipo                     | Fine-tuning Necesario | Facilidad  |
| ---------------------------- | ------------------------ | --------------------- | ---------- |
| **CLIP (OpenAI)**            | Zero-shot classification | No                    | â­â­â­â­â­ |
| **ViT (Vision Transformer)** | Fine-tuned classifier    | SÃ­ (fÃ¡cil)            | â­â­â­â­   |
| **EfficientNet**             | CNN Classifier           | SÃ­ (fÃ¡cil)            | â­â­â­â­   |
| **ResNet-50**                | CNN Classifier           | SÃ­                    | â­â­â­     |

#### CÃ³digo de Ejemplo (CLIP - Zero-shot):

```python
import torch
from transformers import CLIPProcessor, CLIPModel

model = CLIPModel.from_pretrained("openai/clip-vit-large-patch14")
processor = CLIPProcessor.from_pretrained("openai/clip-vit-large-patch14")

# CategorÃ­as de clasificaciÃ³n
categories = [
    "exterior view of a car from outside",
    "interior view of a car dashboard and seats",
    "close-up detail of car parts like engine or wheels"
]

# Procesar imagen
inputs = processor(
    text=categories,
    images=image,
    return_tensors="pt",
    padding=True
)

# Clasificar
outputs = model(**inputs)
probs = outputs.logits_per_image.softmax(dim=1)

# Resultado
category_idx = probs.argmax().item()
categories_map = ["Exterior", "Interior", "Misc"]
classification = categories_map[category_idx]
```

---

### 4ï¸âƒ£ Angle Detection (front/rear/side/quarter)

#### Modelos Recomendados:

| Modelo              | Enfoque        | Dataset Necesario        |
| ------------------- | -------------- | ------------------------ |
| **CLIP**            | Zero-shot      | No                       |
| **Custom CNN**      | Fine-tuned     | ~5K imÃ¡genes etiquetadas |
| **Pose Estimation** | 3D orientation | MÃ¡s complejo             |

#### CÃ³digo de Ejemplo (CLIP):

```python
# Usando CLIP para detectar Ã¡ngulo
angles = [
    "front view of a car showing the headlights and grille",
    "rear view of a car showing the taillights and trunk",
    "side view of a car showing the full profile",
    "front quarter view of a car at 45 degree angle",
    "rear quarter view of a car at 45 degree angle from behind"
]

# Clasificar con CLIP
inputs = processor(text=angles, images=image, return_tensors="pt", padding=True)
outputs = model(**inputs)
probs = outputs.logits_per_image.softmax(dim=1)

angle_map = ["front", "rear", "side", "front-quarter", "rear-quarter"]
detected_angle = angle_map[probs.argmax().item()]
```

---

### 5ï¸âƒ£ License Plate Masking (Enmascarar Placas)

#### Modelos Recomendados:

| Modelo                  | EspecializaciÃ³n         | Licencia   | Regiones |
| ----------------------- | ----------------------- | ---------- | -------- |
| **OpenALPR**            | License plate detection | AGPL-3.0   | Global   |
| **Plate Recognizer**    | API comercial           | Comercial  | Global   |
| **YOLO Custom**         | Fine-tuned for plates   | AGPL-3.0   | Custom   |
| **EasyOCR + Detection** | OCR-based               | Apache 2.0 | Global   |

#### Pipeline Recomendado:

```python
from ultralytics import YOLO
import cv2

# Modelo YOLO entrenado para placas
plate_detector = YOLO("license_plate_detector.pt")

# Detectar placa
results = plate_detector(image)

for box in results[0].boxes:
    x1, y1, x2, y2 = box.xyxy[0].int().tolist()

    # Aplicar blur
    roi = image[y1:y2, x1:x2]
    blurred = cv2.GaussianBlur(roi, (51, 51), 0)
    image[y1:y2, x1:x2] = blurred

    # O aplicar rectÃ¡ngulo blanco
    # cv2.rectangle(image, (x1, y1), (x2, y2), (255, 255, 255), -1)
```

---

### 6ï¸âƒ£ 360Â° Spin Generation

Esto NO requiere IA - es un **viewer web interactivo** que muestra imÃ¡genes en secuencia.

#### TecnologÃ­as Recomendadas:

| TecnologÃ­a           | Tipo               | Licencia | RecomendaciÃ³n |
| -------------------- | ------------------ | -------- | ------------- |
| **360-Image-Viewer** | JavaScript library | MIT      | â­â­â­â­â­    |
| **Three.js**         | 3D library         | MIT      | â­â­â­â­      |
| **Pannellum**        | Panorama viewer    | MIT      | â­â­â­        |
| **Custom React**     | DIY solution       | -        | â­â­â­â­      |

#### ImplementaciÃ³n (React + TypeScript):

```tsx
// Ya implementado en Media360ViewerPage.tsx
// El viewer rota entre frames basado en:
// 1. currentFrame (0 a totalFrames-1)
// 2. Mouse drag / touch para rotar
// 3. Auto-rotation opcional
// 4. Keyboard controls (arrow keys)

// Los frames vienen pre-procesados del backend:
// - Fondo reemplazado
// - Colores normalizados
// - Mismo tamaÃ±o/aspecto
```

---

### 7ï¸âƒ£ Shadow Generation (Sombras Realistas)

#### Modelos Recomendados:

| Modelo                          | Enfoque               | Complejidad |
| ------------------------------- | --------------------- | ----------- |
| **Stable Diffusion Inpainting** | Generative AI         | Alta        |
| **ControlNet (depth/normal)**   | Controlled generation | Alta        |
| **OpenCV Shadow Simulation**    | Algorithmic           | Media       |
| **Photoshop-style Dropshadow**  | CSS/Canvas            | Baja        |

#### Enfoque PrÃ¡ctico (Sin IA):

```python
import cv2
import numpy as np

def add_car_shadow(vehicle_mask, background, opacity=0.4, blur=50, offset=(0, 20)):
    """Agregar sombra simple basada en la mÃ¡scara del vehÃ­culo"""

    # Crear sombra desde la mÃ¡scara
    shadow = np.zeros_like(background)

    # Desplazar mÃ¡scara hacia abajo (sombra debajo del vehÃ­culo)
    shadow_mask = np.roll(vehicle_mask, offset[1], axis=0)
    shadow_mask = np.roll(shadow_mask, offset[0], axis=1)

    # Aplicar blur
    shadow_mask = cv2.GaussianBlur(shadow_mask.astype(float), (blur, blur), 0)

    # Componer sombra
    shadow_layer = (shadow_mask[:,:,None] * opacity * 255).astype(np.uint8)

    # Mezclar con background
    result = cv2.addWeighted(background, 1.0, shadow_layer, -1, 0)

    return result
```

#### Enfoque con IA (Mejor Calidad):

```python
from diffusers import StableDiffusionInpaintPipeline
import torch

# Usar Stable Diffusion para generar sombras realistas
pipe = StableDiffusionInpaintPipeline.from_pretrained(
    "stabilityai/stable-diffusion-2-inpainting",
    torch_dtype=torch.float16
)

# Generar Ã¡rea de sombra
shadow_area_mask = create_shadow_mask(vehicle_mask)

# Inpaint la sombra
result = pipe(
    prompt="realistic car shadow on studio floor, soft shadow",
    image=composite_image,
    mask_image=shadow_area_mask,
    num_inference_steps=30
).images[0]
```

---

### 8ï¸âƒ£ Color/Exposure Correction

#### Herramientas Recomendadas:

| Herramienta          | Tipo        | Enfoque                       |
| -------------------- | ----------- | ----------------------------- |
| **OpenCV**           | AlgorÃ­tmico | CLAHE, histogram equalization |
| **Pillow/PIL**       | AlgorÃ­tmico | Auto contrast, brightness     |
| **scikit-image**     | AlgorÃ­tmico | Exposure correction           |
| **Deep Image Prior** | IA          | Neural enhancement            |
| **Real-ESRGAN**      | IA          | Super resolution + enhance    |

#### CÃ³digo de Ejemplo:

```python
import cv2
import numpy as np
from PIL import Image, ImageEnhance

def auto_enhance_image(image_path):
    """Mejora automÃ¡tica de color y exposiciÃ³n"""

    # Leer imagen
    img = cv2.imread(image_path)

    # 1. Convertir a LAB color space
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)

    # 2. Aplicar CLAHE al canal L (luminosidad)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe.apply(l)

    # 3. Recombinar
    lab = cv2.merge([l, a, b])
    result = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)

    # 4. Ajuste de saturaciÃ³n con PIL
    pil_img = Image.fromarray(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))
    enhancer = ImageEnhance.Color(pil_img)
    pil_img = enhancer.enhance(1.1)  # Slight saturation boost

    return np.array(pil_img)
```

---

### 9ï¸âƒ£ Video Frame Extraction

Esto es trivial con **FFmpeg** u **OpenCV**:

```python
import cv2
import os

def extract_frames(video_path, output_dir, frame_count=36):
    """Extraer N frames equidistantes de un video"""

    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    # Calcular intervalo
    interval = total_frames // frame_count

    os.makedirs(output_dir, exist_ok=True)

    frames = []
    for i in range(frame_count):
        frame_num = i * interval
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)
        ret, frame = cap.read()

        if ret:
            frame_path = os.path.join(output_dir, f"frame_{i:03d}.jpg")
            cv2.imwrite(frame_path, frame)
            frames.append(frame_path)

    cap.release()
    return frames
```

O con **FFmpeg** (mÃ¡s rÃ¡pido):

```bash
# Extraer 36 frames equidistantes
ffmpeg -i video.mp4 -vf "select='not(mod(n\,$(echo "scale=0; $(ffprobe -v error -count_frames -select_streams v:0 -show_entries stream=nb_read_frames -of csv=p=0 video.mp4) / 36" | bc)")'" -vsync vfr frame_%03d.jpg
```

---

### ğŸ”Ÿ Feature Video Generation (Video Promocional)

Esta es la funcionalidad mÃ¡s compleja. Requiere:

#### Modelos Recomendados:

| Modelo                     | Tipo                    | Uso           | Complejidad |
| -------------------------- | ----------------------- | ------------- | ----------- |
| **Runway Gen-3**           | Video generation        | Comercial API | ğŸ”´          |
| **Pika Labs**              | Video generation        | Comercial API | ğŸ”´          |
| **Stable Video Diffusion** | Open-source video       | Self-hosted   | ğŸ”´          |
| **Luma Dream Machine**     | Video generation        | Comercial API | ğŸ”´          |
| **FFmpeg Templates**       | Slideshow + transitions | Self-hosted   | ğŸŸ¡          |

#### Enfoque PrÃ¡ctico (Sin IA Generativa):

```python
import moviepy.editor as mpe

def create_promo_video(images, music_path, output_path):
    """Crear video promocional con transiciones"""

    clips = []
    duration_per_image = 3  # segundos

    for img_path in images:
        clip = mpe.ImageClip(img_path).set_duration(duration_per_image)

        # Agregar efecto Ken Burns (zoom lento)
        clip = clip.resize(lambda t: 1 + 0.1 * t / duration_per_image)

        clips.append(clip)

    # Concatenar con crossfade
    video = mpe.concatenate_videoclips(clips, method="compose")

    # Agregar mÃºsica
    audio = mpe.AudioFileClip(music_path)
    audio = audio.set_duration(video.duration)
    video = video.set_audio(audio)

    # Agregar texto overlay
    txt = mpe.TextClip("Â¡Tu prÃ³ximo vehÃ­culo te espera!",
                       fontsize=50, color='white')
    txt = txt.set_position('center').set_duration(3)

    final = mpe.CompositeVideoClip([video, txt])

    final.write_videofile(output_path, fps=30)
```

---

## ğŸ—ï¸ Arquitectura Propuesta: AIProcessingService

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AI PROCESSING SERVICE (NUEVO)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                         API LAYER (.NET 8)                           â”‚  â”‚
â”‚   â”‚  POST /api/ai-process/background-replace                            â”‚  â”‚
â”‚   â”‚  POST /api/ai-process/segment-vehicle                               â”‚  â”‚
â”‚   â”‚  POST /api/ai-process/classify-image                                â”‚  â”‚
â”‚   â”‚  POST /api/ai-process/mask-license-plate                            â”‚  â”‚
â”‚   â”‚  POST /api/ai-process/generate-360                                  â”‚  â”‚
â”‚   â”‚  GET  /api/ai-process/status/{jobId}                                â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                  â”‚                                          â”‚
â”‚                                  â–¼                                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                       MESSAGE QUEUE (RabbitMQ)                       â”‚  â”‚
â”‚   â”‚  ai.background-replace  â”‚  ai.segment  â”‚  ai.classify  â”‚  ai.360   â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                  â”‚                                          â”‚
â”‚                                  â–¼                                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                    PYTHON AI WORKERS (GPU)                           â”‚  â”‚
â”‚   â”‚                                                                      â”‚  â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚
â”‚   â”‚   â”‚  Worker: SAM2   â”‚  â”‚  Worker: CLIP   â”‚  â”‚  Worker: YOLO   â”‚    â”‚  â”‚
â”‚   â”‚   â”‚  Segmentation   â”‚  â”‚  Classification â”‚  â”‚  Detection      â”‚    â”‚  â”‚
â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚
â”‚   â”‚                                                                      â”‚  â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚  â”‚
â”‚   â”‚   â”‚  Worker: Plate  â”‚  â”‚  Worker: 360    â”‚                          â”‚  â”‚
â”‚   â”‚   â”‚  Masking        â”‚  â”‚  Viewer Gen     â”‚                          â”‚  â”‚
â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚  â”‚
â”‚   â”‚                                                                      â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                  â”‚                                          â”‚
â”‚                                  â–¼                                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                         STORAGE (S3/Spaces)                          â”‚  â”‚
â”‚   â”‚  /processed/{vehicleId}/exterior_001_processed.jpg                  â”‚  â”‚
â”‚   â”‚  /processed/{vehicleId}/360-viewer/frame_001.jpg                    â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’° ComparaciÃ³n de Costos

### Spyne AI (Actual)

| Plan       | Costo    | ImÃ¡genes/mes | Costo por imagen |
| ---------- | -------- | ------------ | ---------------- |
| Starter    | $99/mes  | 500          | $0.20            |
| Pro        | $299/mes | 2,000        | $0.15            |
| Enterprise | Custom   | Unlimited    | ~$0.05-0.10      |

### SoluciÃ³n Propia (GPU Cloud)

| Proveedor          | GPU         | Costo/hora | ImÃ¡genes/hora\* | Costo/imagen |
| ------------------ | ----------- | ---------- | --------------- | ------------ |
| **RunPod**         | A100        | $1.89/hr   | ~500            | $0.004       |
| **Lambda Labs**    | A100        | $1.10/hr   | ~500            | $0.002       |
| **AWS g5.xlarge**  | A10G        | $1.01/hr   | ~300            | $0.003       |
| **DO GPU Droplet** | A100 (80GB) | $4.14/hr   | ~500            | $0.008       |

\*Estimado con SAM2 + composiciÃ³n

### ROI Proyectado

| Escenario       | Spyne (Pro) | SoluciÃ³n Propia | Ahorro           |
| --------------- | ----------- | --------------- | ---------------- |
| 2,000 imgs/mes  | $299        | ~$30 (compute)  | **$269 (90%)**   |
| 10,000 imgs/mes | $1,000+     | ~$100           | **$900 (90%)**   |
| 50,000 imgs/mes | $2,500+     | ~$400           | **$2,100 (84%)** |

---

## ğŸ“‹ Plan de ImplementaciÃ³n

### Fase 1: MVP (2-3 semanas)

| Semana | Tarea                              | Modelo       |
| ------ | ---------------------------------- | ------------ |
| 1      | Setup Python workers con Docker    | -            |
| 1      | Implementar Background Replacement | SAM2 + rembg |
| 2      | Implementar Image Classification   | CLIP         |
| 2      | Implementar License Plate Masking  | YOLO custom  |
| 3      | Integrar con .NET API              | RabbitMQ     |
| 3      | Testing y ajustes                  | -            |

### Fase 2: 360Â° Viewer (1 semana)

| Tarea               | TecnologÃ­a               |
| ------------------- | ------------------------ |
| Frame extraction    | FFmpeg + OpenCV          |
| React 360Â° viewer   | Custom (ya implementado) |
| Backend integration | .NET + Workers           |

### Fase 3: Mejoras (2 semanas)

| Tarea             | TecnologÃ­a           |
| ----------------- | -------------------- |
| Shadow generation | OpenCV + algorithmic |
| Color correction  | CLAHE + auto-enhance |
| Quality scoring   | Custom CNN           |
| Hotspot detection | Object detection     |

---

## ğŸ”§ TecnologÃ­as Necesarias

### Backend (.NET 8)

```xml
<!-- Ya existentes -->
<PackageReference Include="MassTransit.RabbitMQ" />
<PackageReference Include="AWSSDK.S3" />

<!-- Nuevos para AI -->
<PackageReference Include="Microsoft.ML" />
<PackageReference Include="Microsoft.ML.OnnxRuntime" />
```

### Python Workers

```txt
# requirements.txt
torch>=2.0.0
torchvision>=0.15.0
transformers>=4.35.0
segment-anything-2>=1.0.0
ultralytics>=8.0.0
opencv-python>=4.8.0
Pillow>=10.0.0
rembg>=2.0.0
pika>=1.3.0  # RabbitMQ
boto3>=1.28.0  # S3
```

### Infraestructura

```yaml
# docker-compose.ai-workers.yaml
services:
  ai-worker-sam:
    image: ghcr.io/okla/ai-worker-sam:latest
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - RABBITMQ_URL=amqp://rabbitmq:5672
      - S3_BUCKET=okla-media

  ai-worker-clip:
    image: ghcr.io/okla/ai-worker-clip:latest
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

---

## âœ… ConclusiÃ³n

Reemplazar Spyne AI es **100% factible** con modelos open-source, con estas ventajas:

| Aspecto             | Spyne               | SoluciÃ³n Propia |
| ------------------- | ------------------- | --------------- |
| **Costo mensual**   | $299-2,500+         | $30-400         |
| **Control**         | Dependencia externa | 100% interno    |
| **PersonalizaciÃ³n** | Limitada            | Ilimitada       |
| **Latencia**        | ~60-120s            | ~5-30s          |
| **Escalabilidad**   | Limitada por plan   | Infinita (GPU)  |
| **Privacy**         | Datos en Spyne      | Datos propios   |

### Modelos Recomendados (Resumen)

| Funcionalidad | Modelo Primario  | Alternativa    |
| ------------- | ---------------- | -------------- |
| SegmentaciÃ³n  | **SAM 2**        | rembg/UÂ²-Net   |
| ClasificaciÃ³n | **CLIP**         | ViT fine-tuned |
| DetecciÃ³n     | **YOLO v8**      | Detectron2     |
| Placas        | **YOLO custom**  | OpenALPR       |
| 360Â° Viewer   | **React custom** | Three.js       |
| Sombras       | **OpenCV**       | SD Inpainting  |
| Video         | **FFmpeg**       | MoviePy        |

---

**PrÃ³ximo Paso:** Â¿Quieres que implemente el `AIProcessingService` con los workers de Python?

---

_Documento creado: Enero 26, 2026_  
_Autor: Equipo OKLA_
