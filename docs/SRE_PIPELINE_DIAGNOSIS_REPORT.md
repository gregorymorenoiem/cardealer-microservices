# üîß SRE Pipeline Diagnosis & Repair Report

**Date:** February 19‚Äì20, 2026  
**Repository:** `gregorymorenoiem/cardealer-microservices` (branch: `main`)  
**Cluster:** `okla-cluster` (DigitalOcean DOKS, namespace: `okla`)  
**Author:** SRE Diagnosis (Automated)

---

## 1. Resumen Ejecutivo

Se identificaron **5 causas ra√≠z** que afectaban la pipeline de despliegue y la estabilidad del cl√∫ster:

| #   | Causa Ra√≠z                                                                                                                                   | Severidad  | Estado                                               |
| --- | -------------------------------------------------------------------------------------------------------------------------------------------- | ---------- | ---------------------------------------------------- |
| 1   | **Registry secret usa `GITHUB_TOKEN` ef√≠mero (`ghs_*`)** ‚Äî pods nuevos no pueden hacer pull de im√°genes despu√©s de que el workflow termina   | üî¥ Cr√≠tica | ‚úÖ Corregido (workflow + secret temporal)            |
| 2   | **`ocelot.prod.json` contiene comentarios `//` inv√°lidos** ‚Äî el archivo no es JSON v√°lido, impide actualizaci√≥n del ConfigMap                | üü° Media   | ‚úÖ Corregido                                         |
| 3   | **ChatbotService: env var `REDIS_PASSWORD` definido despu√©s de su uso en `$(REDIS_PASSWORD)`** ‚Äî Redis connection string no se resuelve      | üî¥ Cr√≠tica | ‚úÖ Corregido                                         |
| 4   | **ChatbotService: startup probe demasiado agresiva** ‚Äî `/health` tarda >5s por checks de PostgreSQL+Redis, pod muere en startup              | üü† Alta    | ‚úÖ Corregido                                         |
| 5   | **CI build failure: 26 servicios secundarios fallan** ‚Äî errores de compilaci√≥n en servicios no-activos (ContactService, ReviewService, etc.) | üü° Media   | ‚ö†Ô∏è Documentado (no bloquea los 14 servicios activos) |

**Estado final del cl√∫ster: ‚úÖ 15/15 pods activos en Running 1/1. Health check p√∫blico OK (HTTP 200).**

---

## 2. Evidencias del Diagn√≥stico

### 2.1 GitHub Actions ‚Äî Runs Recientes

```
Smart CI/CD (√∫ltimos 10):
  ‚ùå 22208356376 ‚Äî "chore: merge development into main" (26 servicios fallaron)
  ‚úÖ 22205991440 ‚Äî "chore(maintenance): finalize deployment fixes"
  ‚úÖ 22205919412 ‚Äî "chore(maintenance): finalize deployment fixes"
  ‚úÖ 22205503859 ‚Äî "fix(maintenance): add solution file..."
  ‚ùå 22185009583 ‚Äî "fix(maintenance): fix Program.cs syntax/JWT bugs..."

Deploy to Digital Ocean:
  ‚è≠Ô∏è 22208464679 ‚Äî Skipped (CI fall√≥, deploy no se triggere√≥)
  ‚úÖ 22206082721 ‚Äî Success
  ‚úÖ 22205812832 ‚Äî Success
```

**Servicios fallidos en run 22208356376:**

| Categor√≠a        | Servicios                                                                                                                                                                                                                                                                                                                                     | Error                                 |
| ---------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------- |
| Restore failures | ReviewService, SchedulerService, AppointmentService, IdempotencyService, StaffService, BackgroundRemovalService, InventoryManagementService, DealerManagementService, RecommendationService, PaymentService, DealerAnalyticsService, ReportsService, LeadScoringService, RateLimitingService, ComparisonService, AlertService, ApiDocsService | `dotnet restore` failed               |
| Build failures   | ContactService, Vehicle360ProcessingService, ConfigurationService, CRMService, MarketingService, DataProtectionService, AIProcessingService, ServiceDiscovery, VehicleIntelligenceService, IntegrationService                                                                                                                                 | `dotnet build` failed (CS1061 errors) |
| Docker build     | MessageBusService                                                                                                                                                                                                                                                                                                                             | Docker build failed                   |

**Ejemplo de error (ContactService):**

```
error CS1061: 'ContactRequest' does not contain a definition for 'Messages'
error CS1061: 'ContactRequest' does not contain a definition for 'SellerId'
error CS1061: 'ContactRequest' does not contain a definition for 'Status'
error CS1061: 'ContactRequest' does not contain a definition for 'BuyerId'
```

> **Nota:** Estos 26 servicios est√°n en `replicas: 0` (no activos). Los 14 servicios activos (authservice, gateway, frontend-web, etc.) compilaron y se desplegaron correctamente.

### 2.2 Estado de Pods (Pre-diagn√≥stico)

```
chatbotservice-95fc67d77-ln99n   0/1   ImagePullBackOff   (image: chatbotservice:1.0.14)
chatbotservice-fcc649864-7lfg5   1/1   Running            (old pod, still alive from 40h ago)
pg-users, pgclient*, pgquery*    0/1   Completed/Error    (stale debug pods)
test-auth-*, test-curl, curlpod  0/1   Completed          (stale test pods)
```

### 2.3 Registry Secret ‚Äî Token Ef√≠mero

```
Server: ghcr.io
Username: gregorymorenoiem
Password prefix: ghs_swJ8CT...
Type: ‚ö†Ô∏è EPHEMERAL (GitHub Actions token ‚Äî expired)
```

**Causa:** El workflow `deploy-digitalocean.yml` l√≠nea 192 usaba:

```yaml
--docker-password=${{ secrets.GITHUB_TOKEN }}
```

`GITHUB_TOKEN` (`ghs_*`) expira ~1 hora despu√©s de que el workflow termina. Los pods existentes contin√∫an ejecut√°ndose pero nuevos pods no pueden hacer `docker pull`.

### 2.4 Ocelot.prod.json ‚Äî JSON Inv√°lido

```
Archivo: backend/Gateway/Gateway.Api/ocelot.prod.json (2208 l√≠neas)
Error en l√≠nea 2100, columna 5: "Expecting value"
Causa: Comentarios JavaScript-style (//) en JSON est√°ndar

L√≠nea 2100: // ‚îÄ‚îÄ Leads (VehiclesSaleService) ‚îÄ‚îÄ
L√≠nea 2165: // ‚îÄ‚îÄ Invoices (PaymentService) ‚îÄ‚îÄ
```

### 2.5 ChatbotService ‚Äî Redis Connection y Startup Probe

**Problema 1 ‚Äî Env var ordering:**

```yaml
# ‚ùå ANTES (Redis__ConnectionString definido ANTES de REDIS_PASSWORD)
- name: Redis__ConnectionString
  value: "redis:6379,password=$(REDIS_PASSWORD)" # $(REDIS_PASSWORD) = literal
- name: REDIS_PASSWORD # Definido despu√©s ‚Üí no disponible para sustituci√≥n
```

Resultado: El pod arrancaba con `Redis__ConnectionString=redis:6379,password=$(REDIS_PASSWORD)` (texto literal). El health check de Redis fallaba ‚Üí `/health` devolv√≠a 503.

**Problema 2 ‚Äî Startup probe:**

```yaml
# ‚ùå ANTES
startupProbe:
  path: /health # Devuelve 503 hasta que Redis conecta (~20s)
  initialDelaySeconds: 5
  periodSeconds: 5
  failureThreshold: 12 # = 65 segundos total, insuficiente
```

### 2.6 ConfigMap vs Fuente

El ConfigMap `gateway-config` en el cl√∫ster contiene una versi√≥n de `ocelot.json` que **difiere** de `ocelot.prod.json` local. La versi√≥n en el cl√∫ster tiene las rutas de Leads e Invoices; la versi√≥n local ten√≠a JSON inv√°lido (comentarios). Tras la correcci√≥n, ambas versiones son consistentes.

---

## 3. Cambios Aplicados

### 3.1 `deploy-digitalocean.yml` ‚Äî Usar PAT persistente

```diff
- kubectl create secret docker-registry registry-credentials \
-   --docker-server=ghcr.io \
-   --docker-username=${{ github.actor }} \
-   --docker-password=${{ secrets.GITHUB_TOKEN }} \
-   -n okla --dry-run=client -o yaml | kubectl apply -f -
+ # ‚ö†Ô∏è Uses GHCR_PAT (persistent Fine-grained PAT with read:packages scope)
+ # instead of GITHUB_TOKEN (ephemeral, expires after workflow completes).
+ kubectl create secret docker-registry registry-credentials \
+   --docker-server=ghcr.io \
+   --docker-username=${{ github.repository_owner }} \
+   --docker-password=${{ secrets.GHCR_PAT }} \
+   -n okla --dry-run=client -o yaml | kubectl apply -f -
```

**‚ö†Ô∏è ACCI√ìN REQUERIDA:** Crear el secreto `GHCR_PAT` en GitHub Settings:

1. Ir a https://github.com/settings/tokens
2. Crear un **Fine-grained PAT** o **Classic PAT** con scope `read:packages` (y `write:packages` si los workflows suben im√°genes)
3. Guardar como secreto del repositorio:
   ```bash
   gh secret set GHCR_PAT --body "ghp_XXXXXXXXX"
   ```

### 3.2 `ocelot.prod.json` ‚Äî Eliminar comentarios inv√°lidos

Se eliminaron 2 l√≠neas con comentarios JavaScript (`//`) que hac√≠an el JSON inv√°lido:

- L√≠nea 2100: `// ‚îÄ‚îÄ Leads (VehiclesSaleService) ‚îÄ‚îÄ`
- L√≠nea 2165: `// ‚îÄ‚îÄ Invoices (PaymentService) ‚îÄ‚îÄ`

Las rutas de Leads e Invoices se mantienen intactas.

### 3.3 `k8s/chatbotservice.yaml` ‚Äî Fix Redis + Startup Probe

```diff
  # Fix 1: Reorder env vars (REDIS_PASSWORD before its usage)
- - name: Redis__ConnectionString
-   value: "redis:6379,password=$(REDIS_PASSWORD)"
  - name: REDIS_PASSWORD
    valueFrom:
      secretKeyRef:
        name: redis-secrets
        key: REDIS_PASSWORD
+ - name: Redis__ConnectionString
+   value: "redis:6379,password=$(REDIS_PASSWORD)"

  # Fix 2: Relaxed startup probe (300s total instead of 65s)
  startupProbe:
    httpGet:
      path: /health
      port: 8080
-   initialDelaySeconds: 5
-   periodSeconds: 5
-   failureThreshold: 12
+   initialDelaySeconds: 15
+   periodSeconds: 15
+   timeoutSeconds: 10
+   failureThreshold: 20
```

### 3.4 Acciones Directas en el Cl√∫ster

| Acci√≥n                       | Comando                                                            | Resultado                           |
| ---------------------------- | ------------------------------------------------------------------ | ----------------------------------- |
| Reemplazar registry secret   | `kubectl delete/create secret registry-credentials`                | ‚úÖ Token `gho_*` (temporal, ~8hr)   |
| Fijar chatbotservice image   | `kubectl set image deploy/chatbotservice ...chatbotservice:latest` | ‚úÖ Elimin√≥ tag `1.0.14` inaccesible |
| Aplicar manifest actualizado | `kubectl apply -f k8s/chatbotservice.yaml`                         | ‚úÖ Env ordering + probe corregidos  |
| Limpiar pods debug/stale     | `kubectl delete pod pg-users pgclient* pgquery* test-* curlpod`    | ‚úÖ 10 pods eliminados               |

---

## 4. Verificaci√≥n Final

### 4.1 Estado de Pods

```
authservice-59cb968545-mxbbn           1/1   Running
billingservice-85dc5978dd-n6m2l        1/1   Running
chatbotservice-845ff575db-qpr7v        1/1   Running   ‚Üê Fixed
errorservice-cc756b7f6-qxh4b          1/1   Running
frontend-web-688f79948c-6gdfv          1/1   Running
gateway-d58d6c959-qgqbb               1/1   Running
kycservice-5b476c4498-cd2bw            1/1   Running
mediaservice-b4f5f7495-rblcm           1/1   Running
notificationservice-86dd7c5d-vkf7c     1/1   Running
postgres-0                             1/1   Running
rabbitmq-d47f9cb95-n7j8q               1/1   Running
redis-85fdbcb556-9pnb9                 1/1   Running
roleservice-fd85fbb54-4m5l2            1/1   Running
userservice-6d85c6675d-dz9cq           1/1   Running
vehiclessaleservice-6d55dbb7cb-f5z4r   1/1   Running
```

**15/15 pods activos: Running 1/1 ‚úÖ**

### 4.2 Health Checks Internos (desde gateway pod)

```
authservice:          HTTP 200 ‚úÖ
userservice:          HTTP 200 ‚úÖ
roleservice:          HTTP 200 ‚úÖ
vehiclessaleservice:  HTTP 200 ‚úÖ
mediaservice:         HTTP 200 ‚úÖ
notificationservice:  HTTP 200 ‚úÖ
billingservice:       HTTP 200 ‚úÖ
errorservice:         HTTP 200 ‚úÖ
kycservice:           HTTP 200 ‚úÖ
chatbotservice:       HTTP 200 ‚úÖ
frontend-web:         HTTP 200 ‚úÖ
```

### 4.3 Health Check P√∫blico

```bash
$ curl -sf https://okla.com.do/api/health
{"status":"healthy","timestamp":"2026-02-20T04:16:34.266Z","version":"1.0.0","environment":"production"}
# HTTP 200 ‚úÖ
```

### 4.4 ChatbotService Health (Detallado)

```json
{
  "status": "Healthy",
  "checks": [
    { "name": "postgresql", "status": "Healthy", "duration": 64.44 },
    { "name": "redis", "status": "Healthy", "duration": 605.44 }
  ],
  "totalDuration": 611.14
}
```

---

## 5. Recomendaciones

### üî¥ Prioritaria ‚Äî Crear PAT Persistente para GHCR

El secret `registry-credentials` actual usa un token OAuth CLI (`gho_*`) que expira en ~8 horas. **Se necesita un PAT persistente:**

1. Crear un **Classic PAT** con scope `read:packages` + `write:packages`
2. Guardarlo como secreto del repositorio:
   ```bash
   gh secret set GHCR_PAT --body "ghp_XXXXXXXXX"
   ```
3. Actualizar el secret en el cl√∫ster manualmente (o esperar al siguiente deploy):
   ```bash
   kubectl delete secret registry-credentials -n okla
   kubectl create secret docker-registry registry-credentials \
     --docker-server=ghcr.io \
     --docker-username=gregorymorenoiem \
     --docker-password="ghp_XXXXXXXXX" \
     -n okla
   ```

### üü° Mejorar Tagging de Im√°genes

El workflow `chatbot-cicd.yml` usa `sed` para reemplazar `:latest` con `:1.0.X` en el manifest antes de `kubectl apply`. Esto provoca que el deploy deje el tag `1.0.X` en el cl√∫ster, y si la imagen se borra de GHCR o el secret expira, no puede re-pullearse. **Recomendaci√≥n:** Usar siempre `:latest` + `imagePullPolicy: Always`, o pushear ambos tags (`:latest` + `:1.0.X`).

### üü° Corregir 26 Servicios con Build Errors

Los servicios inactivos (replicas: 0) tienen errores de compilaci√≥n que impiden la construcci√≥n de Docker images. Si bien no impactan la operaci√≥n actual, bloquean el CI cuando hay cambios en shared libraries. **Recomendaci√≥n:** Corregir los errores de `ContactService` (propiedad `Messages`, `SellerId`, `BuyerId`, `Status` faltantes en `ContactRequest`) como template para los dem√°s.

### üü¢ Mejora de Health Checks

Considerar implementar `/health/live` (sin dependencias externas) y `/health/ready` (con checks) en todos los servicios. Esto permite usar endpoints distintos para `startupProbe` (live) y `readinessProbe` (ready), evitando reinicios durante inicializaci√≥n lenta.

### üü¢ ConfigMap Gateway ‚Äî Automatizar Sincronizaci√≥n

El ConfigMap `gateway-config` debe actualizarse cada vez que `ocelot.prod.json` cambia. Agregar un paso expl√≠cito al workflow de deploy:

```yaml
- name: Update Gateway ConfigMap
  run: |
    kubectl create configmap gateway-config \
      --from-file=ocelot.json=backend/Gateway/Gateway.Api/ocelot.prod.json \
      -n okla --dry-run=client -o yaml | kubectl apply -f -
    kubectl rollout restart deployment/gateway -n okla
```

### üü¢ Limpieza de Debug Pods

Establecer pol√≠tica de cleanup autom√°tico o usar `Jobs` con `ttlSecondsAfterFinished` para evitar acumulaci√≥n de pods de debug (pg-users, pgclient\*, curlpod, etc.).

---

## 6. Archivos Modificados (Resumen)

| Archivo                                        | Cambio                                                             |
| ---------------------------------------------- | ------------------------------------------------------------------ |
| `.github/workflows/deploy-digitalocean.yml`    | `GITHUB_TOKEN` ‚Üí `GHCR_PAT` para registry secret                   |
| `backend/Gateway/Gateway.Api/ocelot.prod.json` | Eliminados 2 comentarios `//` que invalidaban JSON                 |
| `k8s/chatbotservice.yaml`                      | Reordenado REDIS_PASSWORD antes de su uso + startup probe relajada |

---

_Informe generado el 2026-02-20 ‚Äî 15 pods activos, 0 en error, health p√∫blico OK_
