#!/usr/bin/env python3
"""
OKLA Chatbot LLM â€” Generador de Dataset SintÃ©tico para Fine-Tuning
===================================================================

Genera conversaciones sintÃ©ticas en formato JSONL (chat completion)
para fine-tuning de Llama 3 con QLoRA.

REEMPLAZA COMPLETAMENTE a Google Dialogflow ES.

Uso:
    python generate_dataset.py --count 3000 --output output/
    python generate_dataset.py --count 500 --output output/ --seed 42

Requisitos:
    pip install faker tqdm jsonlines pydantic
"""

import argparse
import json
import os
import random
import re
import sys
from collections import Counter
from copy import deepcopy
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any

try:
    import jsonlines
    from tqdm import tqdm
except ImportError:
    print("Instalando dependencias: pip install tqdm jsonlines")
    os.system(f"{sys.executable} -m pip install tqdm jsonlines")
    import jsonlines
    from tqdm import tqdm

from conversation_templates import (
    INTENT_REGISTRY,
    MULTI_TURN_CHAINS,
    AMBIGUOUS_TEMPLATES,
    BODY_TYPE_SLANG,
    PRICE_EXPRESSIONS,
    AFFIRMATIVES,
)

# ============================================================
# CONFIG
# ============================================================

SCRIPT_DIR = Path(__file__).parent
VEHICLES_FILE = SCRIPT_DIR / "seed_vehicles.json"
DEALERS_FILE = SCRIPT_DIR / "seed_dealers.json"

# Distribution targets (percentage of total)
INTENT_DISTRIBUTION = {
    # Core intents (original 18)
    "VehicleSearch": 0.09,
    "VehicleDetails": 0.07,
    "VehiclePrice": 0.06,
    "FinancingInfo": 0.05,
    "TestDriveSchedule": 0.04,
    "VehicleComparison": 0.04,
    "Greeting": 0.025,
    "CashPurchase": 0.04,
    "VehicleSpecsQuestion": 0.04,
    "DealerHours": 0.03,
    "DealerLocation": 0.03,
    "TradeIn": 0.025,
    "ContactRequest": 0.02,
    "Complaint": 0.015,
    "WarrantyInfo": 0.015,
    "Help": 0.01,
    "Farewell": 0.015,
    "Fallback": 0.025,
    # Phase 3: Edge-case intents (14 new)
    "NegotiatePrice": 0.035,
    "VehicleAvailability": 0.03,
    "InsuranceInfo": 0.03,
    "DocumentsRequired": 0.02,
    "DeliveryInfo": 0.025,
    "VehicleHistory": 0.025,
    "PaymentMethods": 0.02,
    "ReturnPolicy": 0.025,
    "MaintenanceCost": 0.03,
    "OutOfScope": 0.015,
    "LanguageBarrier": 0.01,
    "ColorAvailability": 0.02,
    "UrgentPurchase": 0.035,
    "NewVsUsed": 0.02,
    # Legal compliance: refusal of illegal requests
    "LegalRefusal": 0.03,
    # Inventory grounding: not found responses
    "VehicleNotInInventory": 0.04,
    # Negative responses, conflict & escalation
    "UserObjection": 0.03,
    "FrustratedUser": 0.02,
    "RequestHumanAgent": 0.02,
}

# Conversation type distribution
CONV_TYPE_DISTRIBUTION = {
    "single_turn": 0.12,       # 1 user/assistant pair
    "short_multi_turn": 0.55,  # 2-4 turns
    "long_multi_turn": 0.33,   # 5-10 turns (Phase 5: increased for mega chains)
}

# System prompt template
SYSTEM_PROMPT_TEMPLATE = """Eres {bot_name}, el asistente virtual de {dealer_name}, un concesionario de vehÃ­culos en RepÃºblica Dominicana.

IDENTIDAD Y PERSONALIDAD:
- Tu nombre es {bot_name}.
- Representas a {dealer_name}.
- Hablas en espaÃ±ol dominicano amigable y profesional.
- Entiendes modismos dominicanos: "yipeta" (SUV), "guagua" (vehÃ­culo/bus), "carro" (auto), "motor"/"moto" (motocicleta), "pela'o" (barato), "chivo" (buena oferta), "vaina" (cosa), "tato" (ok/de acuerdo).
- NUNCA inventes informaciÃ³n. Si no sabes algo, ofrece conectar con un agente.
- SÃ© conciso: respuestas de 2-4 oraciones mÃ¡ximo.
- Usa emojis moderadamente (1-2 por mensaje).

REGLAS:
1. Responde SIEMPRE en espaÃ±ol dominicano amigable y profesional.
2. Responde SIEMPRE en formato JSON con los campos: response, intent, confidence, isFallback, parameters, leadSignals, suggestedAction, quickReplies.
3. NUNCA inventes precios, especificaciones o datos que no estÃ©n en el inventario proporcionado.
4. NUNCA des asesorÃ­a legal, financiera vinculante o diagnÃ³sticos mecÃ¡nicos.
5. Respeta la Ley 358-05 (ProtecciÃ³n al Consumidor), Ley 172-13 (ProtecciÃ³n de Datos) y normativas DGII.
6. Si no sabes algo, admÃ­telo y ofrece conectar con un asesor humano.
7. Detecta seÃ±ales de compra (presupuesto, test drive, financiamiento, datos de contacto).
8. MÃ¡ximo 3-4 vehÃ­culos por respuesta de bÃºsqueda.
9. Si el usuario dice que NO quiere financiamiento o que paga al contado, NO ofrezcas financiamiento.
10. Para especificaciones tÃ©cnicas, usa SOLO los datos del INVENTARIO DISPONIBLE. Si un dato no aparece, redirige al asesor.

REGLAS DE INVENTARIO (CRÃTICAS â€” anti-alucinaciÃ³n):
11. SOLO puedes recomendar, mencionar o detallar vehÃ­culos que aparezcan en INVENTARIO DISPONIBLE.
12. Si el usuario pregunta por una marca, modelo o tipo de vehÃ­culo que NO estÃ¡ en INVENTARIO DISPONIBLE, di claramente "Actualmente no tenemos [marca/modelo] en nuestro inventario" y sugiere alternativas del inventario.
13. NUNCA inventes vehÃ­culos, precios, especificaciones, colores ni caracterÃ­sticas que no estÃ©n explÃ­citamente listados en INVENTARIO DISPONIBLE.
14. Si el usuario pregunta por una especificaciÃ³n (HP, torque, puertas, asientos, tracciÃ³n, etc.) que NO aparece en los datos del inventario, di "Esa informaciÃ³n no estÃ¡ disponible en mi sistema, puedo conectarte con un asesor que te la confirme."
15. Cuando presentes vehÃ­culos, usa EXACTAMENTE los precios y datos del INVENTARIO DISPONIBLE â€” nunca redondees ni aproximes.
16. Si no hay vehÃ­culos en el inventario que coincidan con lo que busca el usuario, dilo honestamente y ofrece mostrar lo que SÃ tienes disponible.

PROHIBICIONES LEGALES (RepÃºblica Dominicana):
- NUNCA facilites evasiÃ³n fiscal (Ley 11-92 / DGII). Toda venta DEBE facturarse con ITBIS y NCF.
- NUNCA aceptes transacciones anÃ³nimas ni sin identificaciÃ³n (Ley 155-17 contra Lavado de Activos).
- NUNCA compartas datos personales de clientes (Ley 172-13 de ProtecciÃ³n de Datos).
- NUNCA ocultes defectos ni hagas publicidad engaÃ±osa (Ley 358-05 Pro-Consumidor).
- NUNCA falsifiques documentos, kilometraje ni historial vehicular.
- NUNCA facilites la falsificaciÃ³n de documentos de ningÃºn tipo.
- NUNCA discrimines por nacionalidad, gÃ©nero, edad o condiciÃ³n (ConstituciÃ³n Art. 39).
- NUNCA vendas vehÃ­culos sin documentaciÃ³n legal completa (matrÃ­cula, marbete, traspaso, seguro).
- Toda informaciÃ³n de clientes es confidencial y no se comparte.
- Si el usuario solicita algo ilegal, rechaza la solicitud con cortesÃ­a, cita la ley aplicable y redirige a alternativas legales.

INFORMACIÃ“N DEL DEALER:
- Nombre: {dealer_name}
- UbicaciÃ³n: {dealer_location}
- TelÃ©fono: {dealer_phone}
- Horario: Lunes-Viernes {hours_weekday}, SÃ¡bados {hours_saturday}
- Financiamiento con: {financing_partners}
- Trade-in: {trade_in}

INVENTARIO DISPONIBLE:
{inventory_summary}

IMPORTANTE: SOLO puedes recomendar vehÃ­culos listados arriba. Si el usuario pregunta por una marca, modelo o especificaciÃ³n que NO aparece aquÃ­, di claramente que no lo tienes en inventario y sugiere alternativas de esta lista."""


# ============================================================
# HELPERS
# ============================================================

def load_json(path: Path) -> list:
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def build_inventory_summary(vehicles: list, max_vehicles: int = 15) -> str:
    """Build a compact inventory summary for the system prompt.
    Format MUST match BuildInventorySection() in SessionCommandHandlers.cs (production).
    Fields: Make Model Year Trim | Price | FuelType | Transmission | Mileage | Color | ID
    """
    selected = random.sample(vehicles, min(max_vehicles, len(vehicles)))
    lines = []
    for v in selected:
        sale_tag = " ğŸ·ï¸OFERTA" if v.get("isOnSale") else ""
        lines.append(
            f"- {v['make']} {v['model']} {v['year']} {v.get('trim', '')} | "
            f"RD${v['price']:,.0f}{sale_tag} | {v['fuelType']} | {v['transmission']} | "
            f"{v['mileage']:,}km | {v.get('exteriorColor', 'N/A')} | ID:{v['id']}"
        )
    return "\n".join(lines)


def build_system_prompt(dealer: dict, vehicles: list) -> str:
    """Build the full system prompt with dealer context."""
    hours = dealer.get("businessHours", {})
    weekday = hours.get("monday", {})
    saturday = hours.get("saturday", {})

    return SYSTEM_PROMPT_TEMPLATE.format(
        bot_name=dealer.get("botName", "OKLA AI"),
        dealer_name=dealer["name"],
        dealer_location=dealer["location"],
        dealer_phone=dealer["phone"],
        hours_weekday=f"{weekday.get('open', '8:00')}-{weekday.get('close', '18:00')}" if weekday else "8:00-18:00",
        hours_saturday=f"{saturday.get('open', '9:00')}-{saturday.get('close', '14:00')}" if saturday else "Cerrado",
        financing_partners=", ".join(dealer.get("financingPartners", ["Consultar"])),
        trade_in="SÃ­" if dealer.get("tradeInAccepted") else "No",
        inventory_summary=build_inventory_summary(vehicles),
    )


def fill_vehicle_placeholders(template: str, vehicle: dict = None, vehicles: list = None) -> str:
    """Replace {make}, {model}, {year} placeholders in user templates."""
    text = template
    if vehicle:
        text = text.replace("{make}", vehicle["make"])
        text = text.replace("{model}", vehicle["model"])
        text = text.replace("{year}", str(vehicle["year"]))

    if vehicles and len(vehicles) >= 2:
        text = text.replace("{make1}", vehicles[0]["make"])
        text = text.replace("{model1}", vehicles[0]["model"])
        text = text.replace("{make2}", vehicles[1]["make"])
        text = text.replace("{model2}", vehicles[1]["model"])

    # Trade-in placeholders
    old_makes = ["Toyota", "Honda", "Hyundai", "Nissan", "Kia", "Chevrolet"]
    old_models = ["Corolla", "Civic", "Accent", "Sentra", "Forte", "Aveo"]
    old_years = ["2018", "2019", "2020", "2016", "2017"]
    text = text.replace("{make_old}", random.choice(old_makes))
    text = text.replace("{year_old}", random.choice(old_years))

    # Contact placeholders
    phones = ["809-555-1234", "829-555-4567", "849-555-7890", "809-555-0000"]
    names = ["Juan PÃ©rez", "MarÃ­a GarcÃ­a", "Carlos RodrÃ­guez", "Ana MartÃ­nez", "Pedro SÃ¡nchez",
             "Laura DÃ­az", "JosÃ© HernÃ¡ndez", "Carmen LÃ³pez"]
    text = text.replace("{phone}", random.choice(phones))
    text = text.replace("{name}", random.choice(names))

    return text


def select_vehicles_for_intent(intent: str, vehicles: list) -> tuple:
    """Select appropriate vehicles based on intent."""
    if intent == "VehicleComparison":
        # Pick 2 vehicles of similar type
        body_types = {}
        for v in vehicles:
            bt = v.get("bodyType", "Other")
            body_types.setdefault(bt, []).append(v)

        # Try to find 2 of same type
        for bt, vlist in body_types.items():
            if len(vlist) >= 2:
                pair = random.sample(vlist, 2)
                return pair[0], pair

        # Fallback: any 2
        pair = random.sample(vehicles, 2)
        return pair[0], pair

    elif intent == "VehicleSearch":
        # Return 2-3 vehicles
        count = random.choice([2, 3])
        selected = random.sample(vehicles, min(count, len(vehicles)))
        return selected[0], selected

    else:
        # Single vehicle
        v = random.choice(vehicles)
        return v, [v]


def add_typos_and_slang(text: str, probability: float = 0.15) -> str:
    """Randomly add Dominican Spanish variations, typos, and WhatsApp-style text.

    Applies up to 4 independent augmentation layers:
      1. Word-level Dominican slang substitutions (~60 entries)
      2. Accent stripping  (Ã¡â†’a, Ã©â†’e, etc.)
      3. Character-level typos (swap, drop, double, adjacent-key)
      4. Casing variation (lowercase / CAPS / no-caps)
    Each layer fires independently based on sub-probabilities, so the same
    message can receive multiple transformations at once.
    """
    if random.random() > probability:
        return text

    # --- Layer 1: Dominican slang / WhatsApp word substitutions ---
    SLANG_MAP = {
        # Common shortenings
        "que": ["q", "ke", "k"],
        "estÃ¡": ["ta", "esta"],
        "estÃ¡n": ["tan", "estan"],
        "estoy": ["toy"],
        "para": ["pa"],
        "vamos": ["vamo"],
        "verdad": ["velda", "vdd"],
        "bueno": ["weno", "bno"],
        "nada": ["na"],
        "todo": ["to", "tol"],
        "tambiÃ©n": ["tb", "tmb", "tambien"],
        "porque": ["xq", "pq", "porq"],
        "como": ["cm", "kmo"],
        "tengo": ["tngo"],
        "tiene": ["tne"],
        "tienen": ["tnen"],
        "quiero": ["kiero", "qiero"],
        "puede": ["pue"],
        "pueden": ["puen"],
        "necesito": ["ncsito", "necesit", "nesesito"],
        "precio": ["presio", "precio"],
        "cuÃ¡nto": ["cuanto", "cnto"],
        "cuanto": ["cnto", "cuant"],
        "carro": ["caro", "karro"],
        "carros": ["caros", "karros"],
        "vehÃ­culo": ["vehiculo", "vehiclo"],
        "disponible": ["disponble", "disponiblee"],
        "informaciÃ³n": ["info", "informacion"],
        "telÃ©fono": ["telefono", "tel"],
        "nÃºmero": ["numero", "num"],
        "dÃ³nde": ["donde", "dnd"],
        "dÃ­game": ["digame", "dgame"],
        "gracias": ["gracia", "grax", "grs", "ty"],
        "por favor": ["porfa", "xfa", "porfavor", "x favor"],
        "hola": ["ola", "holaa", "holaa!"],
        "buenos": ["bno", "wenos"],
        "dÃ­as": ["dia", "dias"],
        "mucho": ["muxo", "mcho"],
        "ahora": ["aora", "ahorita"],
        "favor": ["favo"],
        "ustedes": ["uds", "ustede"],
        "nosotros": ["nosotro"],
        "maÃ±ana": ["manana", "mÃ±na"],
        "hoy": ["hoyy"],
        "aquÃ­": ["aki", "aqui", "aqii"],
        "mÃ¡s": ["mas", "ma"],
        "algÃºn": ["algun", "algn"],
        "hasta": ["ata", "hta"],
        "dinero": ["cuarto", "chelito"],
        "usted": ["uste", "ud"],
        "cÃ³mo": ["como", "cm"],
        "fiado": ["fiao"],
        "rÃ¡pido": ["rapido", "rapdo"],
        "hermano": ["mano", "manin"],
        "amigo": ["loco", "pana"],
        "estÃ¡ bien": ["ta bien", "ta bn"],
        "no sÃ©": ["nose", "no c"],
        "quÃ© tal": ["klk", "dime"],
        "de verdad": ["deverdad", "en serio", "de velda"],
        "por quÃ©": ["xq", "porq"],
        "con": ["cn"],
        "sin": ["sn"],
        "hay": ["ai", "hayy"],
    }

    # Dominican interjections to randomly prepend (low probability)
    DOMINICAN_INTERJECTIONS = [
        "Dimelo,", "Klk,", "Oye,", "Mano,", "Dime a ver,",
        "Eyyy,", "Alo,", "Weepa,", "Eh,", "Compai,",
    ]

    # WhatsApp-style suffixes / reactions
    WHATSAPP_SUFFIXES = [
        " ğŸ‘€", " ğŸ¤”", " ğŸ™", " ğŸ’ª", " ğŸš—", " pls", " plz", " !", " !!",
        " ???", " ?!", " porfa", " ğŸ”¥", " dale", " ok?",
    ]

    result_words = text.split()

    # 1a. Word-level slang substitution (30% chance per matching word)
    for i, word in enumerate(result_words):
        # Strip punctuation for lookup, preserve it for output
        stripped = word.lower().strip("Â¿?Â¡!.,;:()")
        trailing = ""
        if word and word[-1] in "Â¿?Â¡!.,;:()":
            trailing = word[-1]
            word_clean = word[:-1]
        else:
            word_clean = word
            trailing = ""

        if stripped in SLANG_MAP and random.random() < 0.30:
            replacement = random.choice(SLANG_MAP[stripped])
            result_words[i] = replacement + trailing

    # 1b. Two-word slang substitution (check bigrams)
    BIGRAM_SLANG = {
        "por favor": ["porfa", "xfa", "porfis", "x favor"],
        "estÃ¡ bien": ["ta bien", "ta bn", "ok", "dale"],
        "no sÃ©": ["nose", "no c", "ni idea"],
        "quÃ© tal": ["klk", "q tal", "dime"],
        "de verdad": ["deverdad", "de velda", "en serio"],
        "por quÃ©": ["xq", "porq", "pq"],
        "cÃ³mo estÃ¡": ["como ta", "cm ta"],
        "muchas gracias": ["mil gracias", "grax", "thank you", "tysm"],
        "buenas tardes": ["bnas tardes", "buena tarde"],
        "buenas noches": ["bnas noches", "buena noche"],
        "buenos dÃ­as": ["buen dia", "bno dia", "buenos dia"],
        "me puede": ["me pue", "me pueden"],
        "lo que": ["lo q", "lo ke"],
        "mÃ¡s o menos": ["maso", "masomeno"],
        "cuÃ¡nto cuesta": ["cuanto e", "cuant cuesta", "a cuanto"],
        "cuÃ¡nto vale": ["cuanto vale", "cuant sale"],
    }

    joined = " ".join(result_words)
    for bigram, options in BIGRAM_SLANG.items():
        if bigram in joined.lower() and random.random() < 0.35:
            # Case-insensitive replace (first occurrence only)
            pattern = re.compile(re.escape(bigram), re.IGNORECASE)
            joined = pattern.sub(random.choice(options), joined, count=1)
    result_words = joined.split()

    # --- Layer 2: Accent stripping (40% chance if triggered) ---
    if random.random() < 0.40:
        ACCENT_MAP = str.maketrans("Ã¡Ã©Ã­Ã³ÃºÃÃ‰ÃÃ“ÃšÃ±Ã‘", "aeiouAEIOUnN")
        result_words = [w.translate(ACCENT_MAP) for w in result_words]

    # --- Layer 3: Character-level typos (25% chance, then per-word) ---
    if random.random() < 0.25:
        ADJACENT_KEYS = {
            'a': 'sqw', 'b': 'vgn', 'c': 'xdv', 'd': 'sfec', 'e': 'wrd',
            'f': 'dgrc', 'g': 'fhtv', 'h': 'gjyn', 'i': 'uok', 'j': 'hkum',
            'k': 'jlio', 'l': 'kop', 'm': 'nj', 'n': 'bmh', 'o': 'iplk',
            'p': 'ol', 'q': 'wa', 'r': 'edt', 's': 'adwz', 't': 'rfgy',
            'u': 'yij', 'v': 'cbf', 'w': 'qase', 'x': 'zsdc', 'y': 'tuh',
            'z': 'xas',
        }
        for i, word in enumerate(result_words):
            if len(word) < 3 or random.random() > 0.20:
                continue
            typo_type = random.choice(["swap", "drop", "double", "adjacent"])
            chars = list(word)
            if typo_type == "swap" and len(chars) >= 3:
                # Swap two adjacent characters
                idx = random.randint(0, len(chars) - 2)
                chars[idx], chars[idx + 1] = chars[idx + 1], chars[idx]
            elif typo_type == "drop" and len(chars) >= 4:
                # Drop a random character (not first or last)
                idx = random.randint(1, len(chars) - 2)
                chars.pop(idx)
            elif typo_type == "double" and len(chars) >= 3:
                # Double a random character
                idx = random.randint(0, len(chars) - 1)
                chars.insert(idx, chars[idx])
            elif typo_type == "adjacent":
                # Replace with adjacent key
                idx = random.randint(0, len(chars) - 1)
                c = chars[idx].lower()
                if c in ADJACENT_KEYS:
                    chars[idx] = random.choice(ADJACENT_KEYS[c])
            result_words[i] = "".join(chars)

    # --- Layer 4: Casing variation (20% chance) ---
    if random.random() < 0.20:
        case_style = random.choice(["lower", "no_caps", "first_lower"])
        if case_style == "lower":
            # All lowercase (very common in WhatsApp)
            result_words = [w.lower() for w in result_words]
        elif case_style == "no_caps":
            # Remove capitalization except proper nouns (just lowercase first char)
            result_words = [w[0].lower() + w[1:] if len(w) > 1 and w[0].isupper() else w
                            for w in result_words]
        elif case_style == "first_lower":
            # Only first word lowercase
            if result_words:
                result_words[0] = result_words[0].lower()

    # --- Layer 5: Prepend Dominican interjection (8% chance) ---
    if random.random() < 0.08 and result_words:
        # Don't add if already starts with an interjection-like word
        first_lower = result_words[0].lower().rstrip(",")
        interjection_starts = {"dimelo", "klk", "oye", "mano", "eyyy", "alo", "weepa", "compai", "dime"}
        if first_lower not in interjection_starts:
            result_words.insert(0, random.choice(DOMINICAN_INTERJECTIONS))

    # --- Layer 6: Append WhatsApp suffix (10% chance) ---
    if random.random() < 0.10 and result_words:
        suffix = random.choice(WHATSAPP_SUFFIXES)
        # Remove trailing punctuation before adding suffix
        last = result_words[-1]
        if last and last[-1] in "?!.":
            result_words[-1] = last.rstrip("?!.")
        result_words[-1] = result_words[-1] + suffix

    return " ".join(result_words)


# ============================================================
# EMOJI REDUCTION (Phase 5 â€” M4)
# ============================================================

import unicodedata

def _count_emojis(text: str) -> int:
    """Count emoji characters in text."""
    return sum(1 for ch in text
               if unicodedata.category(ch) in ('So', 'Sk') or ord(ch) > 0x1F000)

def reduce_emojis(response_text: str, max_emojis: int = 5) -> str:
    """Randomly strip excess emojis from a response string.

    If the response contains more than `max_emojis` emoji characters,
    randomly remove extras to bring the count down to `max_emojis`.
    This reduces the 'emoji saturation' finding (M4) while keeping
    responses feeling natural.
    """
    emoji_positions = [
        i for i, ch in enumerate(response_text)
        if unicodedata.category(ch) in ('So', 'Sk') or ord(ch) > 0x1F000
    ]
    if len(emoji_positions) <= max_emojis:
        return response_text

    # Decide how many to keep: between max_emojis/2 and max_emojis
    keep_count = random.randint(max(1, max_emojis // 2), max_emojis)
    keep_set = set(random.sample(emoji_positions, keep_count))

    chars = []
    for i, ch in enumerate(response_text):
        if i in keep_set or i not in set(emoji_positions):
            chars.append(ch)
    # Clean up double spaces left by removal
    result = ''.join(chars)
    result = re.sub(r'  +', ' ', result)
    return result.strip()


def apply_emoji_reduction(assistant_content: str, probability: float = 0.40) -> str:
    """Parse assistant JSON, reduce emojis in 'response' field, re-serialize."""
    if random.random() > probability:
        return assistant_content
    try:
        data = json.loads(assistant_content)
        if 'response' in data and isinstance(data['response'], str):
            data['response'] = reduce_emojis(data['response'],
                                              max_emojis=random.randint(3, 6))
        return json.dumps(data, ensure_ascii=False)
    except (json.JSONDecodeError, KeyError):
        return assistant_content


# ============================================================
# CONTEXT CONTINUITY (Phase 6 â€” Context Awareness)
# ============================================================
# Injects natural continuity phrases into multi-turn responses
# so the model learns to reference previous conversation context.
# This teaches anaphora resolution ("esa" = the vehicle from turn N-1)
# and conversational flow ("como te mencionÃ©", "sobre lo que buscas").
# ============================================================

# Map intent â†’ how a human would refer back to that topic
_INTENT_TOPIC_MAP = {
    "Greeting":            None,  # Don't reference greetings
    "Farewell":            None,
    "Fallback":            None,
    "OutOfScope":          None,
    "LanguageBarrier":     None,
    "Help":                "la ayuda que necesitas",
    "VehicleSearch":       "tu bÃºsqueda",
    "VehicleDetails":      "el vehÃ­culo que estamos viendo",
    "VehiclePrice":        "el precio que consultaste",
    "VehicleComparison":   "la comparaciÃ³n que hicimos",
    "VehicleSpecsQuestion":"las especificaciones",
    "VehicleAvailability": "la disponibilidad",
    "VehicleHistory":      "el historial del vehÃ­culo",
    "FinancingInfo":       "el financiamiento",
    "TestDriveSchedule":   "la prueba de manejo",
    "DealerHours":         "nuestro horario",
    "DealerLocation":      "nuestra ubicaciÃ³n",
    "ContactRequest":      "tu solicitud de contacto",
    "Complaint":           "tu inquietud",
    "TradeIn":             "el trade-in",
    "WarrantyInfo":        "la garantÃ­a",
    "CashPurchase":        "la compra al contado",
    "NegotiatePrice":      "la negociaciÃ³n",
    "InsuranceInfo":       "el seguro",
    "DocumentsRequired":   "los documentos",
    "DeliveryInfo":        "la entrega",
    "PaymentMethods":      "las formas de pago",
    "ReturnPolicy":        "la polÃ­tica de devoluciÃ³n",
    "MaintenanceCost":     "los costos de mantenimiento",
    "ColorAvailability":   "los colores disponibles",
    "UrgentPurchase":      "tu compra urgente",
    "NewVsUsed":           "los vehÃ­culos nuevos y usados",
    "LegalRefusal":        None,  # Don't reference illegal requests
    "VehicleNotInInventory": None,  # Don't reference unavailable vehicles
    "UserObjection":       "tu consulta",
    "FrustratedUser":      None,  # Don't reference frustration
    "RequestHumanAgent":   None,  # Don't reference transfer requests
}

# Continuity phrase templates â€” {vehicle} and {topic} are replaced dynamically
_CONTINUITY_WITH_VEHICLE = [
    "Sobre {vehicle} que estamos viendo, ",
    "Siguiendo con {vehicle}, ",
    "En cuanto a {vehicle} que te interesa, ",
    "Respecto a {vehicle}, ",
    "Con relaciÃ³n a {vehicle} que consultaste, ",
    "Volviendo a {vehicle}, ",
    "Hablando de {vehicle}, ",
    "Para {vehicle} que mencionaste, ",
]

_CONTINUITY_WITH_TOPIC = [
    "Siguiendo con {topic}, ",
    "Sobre {topic} que hablamos, ",
    "Con respecto a {topic}, ",
    "Volviendo a {topic}, ",
    "En cuanto a {topic}, ",
    "Respecto a lo que preguntaste sobre {topic}, ",
]

_CONTINUITY_GENERIC = [
    "Claro, siguiendo con tu consulta, ",
    "Perfecto, continuando, ",
    "Muy bien, con respecto a eso, ",
    "Entendido, sobre lo que me preguntas, ",
    "Buena pregunta, ",
    "Claro que sÃ­, ",
    "Por supuesto, ",
    "Con gusto te explico, ",
    "Excelente pregunta, ",
    "Dale, mira, ",
    "Okay, te cuento, ",
    "SÃ­ claro, ",
]


def inject_context_continuity(
    assistant_json: str,
    turn_index: int,
    previous_intent: str | None,
    current_vehicle: dict | None,
    probability: float = 0.45,
) -> str:
    """Inject a contextual continuity phrase into an assistant response.

    For turn 2+ in multi-turn conversations, prepend a phrase that
    references the previous topic and/or current vehicle, teaching the
    model to maintain conversational context.

    Args:
        assistant_json: Serialized JSON string of the assistant response.
        turn_index: 0-based index of the current turn in the conversation.
        previous_intent: The intent from the previous turn (or None).
        current_vehicle: The vehicle dict being discussed (or None).
        probability: Chance of injecting a continuity phrase (0-1).

    Returns:
        Modified assistant JSON string with continuity phrase prepended.
    """
    # Only apply to turn 2+ (skip the first response)
    if turn_index < 1:
        return assistant_json

    # Skip with probability
    if random.random() > probability:
        return assistant_json

    try:
        data = json.loads(assistant_json)
    except json.JSONDecodeError:
        return assistant_json

    response = data.get("response", "")
    current_intent = data.get("intent", "")

    # Don't inject continuity into greetings, farewells, fallbacks, legal refusals
    if current_intent in ("Greeting", "Farewell", "Fallback", "OutOfScope", "LanguageBarrier", "LegalRefusal", "FrustratedUser", "RequestHumanAgent", "VehicleNotInInventory"):
        return assistant_json

    # Build vehicle label like "la Toyota RAV4 2024"
    vehicle_label = None
    if current_vehicle:
        make = current_vehicle.get("make", "")
        model = current_vehicle.get("model", "")
        year = current_vehicle.get("year", "")
        if make and model:
            vehicle_label = f"la {make} {model} {year}".strip()

    # Decide which type of continuity phrase to use
    # Priority: vehicle-specific > topic-specific > generic
    phrase = None

    if vehicle_label and random.random() < 0.50:
        # 50% chance: reference the specific vehicle
        template = random.choice(_CONTINUITY_WITH_VEHICLE)
        phrase = template.replace("{vehicle}", vehicle_label)
    elif previous_intent and previous_intent in _INTENT_TOPIC_MAP:
        topic = _INTENT_TOPIC_MAP[previous_intent]
        if topic and random.random() < 0.60:
            # 60% chance: reference the previous topic
            template = random.choice(_CONTINUITY_WITH_TOPIC)
            phrase = template.replace("{topic}", topic)

    # Fallback to generic continuity
    if phrase is None:
        phrase = random.choice(_CONTINUITY_GENERIC)

    # Prepend the phrase â€” lowercase the first letter of the original response
    # if the phrase ends with ", " and the response starts with uppercase
    if response and response[0].isupper() and phrase.endswith(", "):
        # Check if response starts with emoji â€” don't lowercase emojis
        first_char = response[0]
        if first_char.isalpha():
            response = response[0].lower() + response[1:]

    data["response"] = phrase + response

    return json.dumps(data, ensure_ascii=False)


# ============================================================
# CONVERSATION GENERATOR
# ============================================================

def generate_single_turn(dealer: dict, vehicles: list, intent: str) -> dict:
    """Generate a single-turn conversation (1 user + 1 assistant)."""
    # Phase 5: 15% chance to use an ambiguous template instead
    # (increased from 10% to fill the 0.40-0.70 confidence gap â€” WARN-1)
    if random.random() < 0.15 and AMBIGUOUS_TEMPLATES:
        matching = [a for a in AMBIGUOUS_TEMPLATES if intent in a["intents"]]
        if matching:
            amb = random.choice(matching)
            intent = random.choice(amb["intents"])  # pick one plausible intent
            # Will use the ambiguous text as user_template below
            amb_text = amb["text"]
        else:
            amb_text = None
    else:
        amb_text = None

    registry = INTENT_REGISTRY.get(intent)
    if not registry:
        return None

    vehicle, vehicle_list = select_vehicles_for_intent(intent, vehicles)

    # Pick user message
    user_template = amb_text if amb_text else random.choice(registry["user_templates"])

    # Pre-generate consistent name/phone for intents that use {name}/{phone}
    pre_name = None
    pre_phone = None
    if intent in ("ContactRequest", "CashPurchase") and ("{name}" in user_template or "{phone}" in user_template):
        name_pool = ["Juan PÃ©rez", "MarÃ­a GarcÃ­a", "Carlos RodrÃ­guez",
                     "Ana MartÃ­nez", "Pedro SÃ¡nchez", "Laura DÃ­az",
                     "Gregory Moreno", "Carmen LÃ³pez"]
        if "{name}" in user_template:
            pre_name = random.choice(name_pool)
            user_template = user_template.replace("{name}", pre_name)
        if "{phone}" in user_template:
            pre_phone = f"809-555-{random.randint(1000,9999)}"
            user_template = user_template.replace("{phone}", pre_phone)

    user_msg = fill_vehicle_placeholders(user_template, vehicle, vehicle_list)
    user_msg = add_typos_and_slang(user_msg, 0.35)

    # Generate assistant response
    kwargs = {}
    if registry["requires_vehicle"]:
        if intent == "VehicleComparison":
            kwargs["vehicles"] = vehicle_list
        elif intent == "VehicleSearch":
            kwargs["vehicles"] = vehicle_list
            kwargs["bodyType"] = vehicle.get("bodyType")
            kwargs["maxPrice"] = vehicle.get("price")
        elif intent == "VehicleSpecsQuestion":
            kwargs["vehicle"] = vehicle
        else:
            kwargs["vehicle"] = vehicle
    else:
        # Some non-vehicle intents can optionally reference a vehicle
        if intent in ("FinancingInfo", "TestDriveSchedule", "WarrantyInfo",
                      "NegotiatePrice", "InsuranceInfo", "VehicleHistory",
                      "MaintenanceCost", "ColorAvailability") and random.random() < 0.5:
            kwargs["vehicle"] = vehicle
        elif intent == "VehicleAvailability":
            kwargs["vehicle"] = vehicle
        elif intent == "CashPurchase":
            if random.random() < 0.6:
                kwargs["vehicle"] = vehicle
            # Only use name/phone if user explicitly provided them in the message
            if pre_name:
                kwargs["name"] = pre_name
            if pre_phone:
                kwargs["phone"] = pre_phone

    response = registry["response_fn"](dealer, **kwargs)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # WARN-1 FIX: Reduce confidence for ambiguous templates to fill
    # the 0.40â€“0.70 gap in the confidence distribution.
    # When the user's message is genuinely ambiguous (matching 2+ intents),
    # the model should output medium confidence, NOT high confidence.
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if amb_text is not None:
        response["confidence"] = round(random.uniform(0.40, 0.70), 2)

    assistant_msg = json.dumps(response, ensure_ascii=False)
    # Phase 5: emoji reduction
    assistant_msg = apply_emoji_reduction(assistant_msg)

    system_prompt = build_system_prompt(dealer, vehicles)

    return {
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_msg},
            {"role": "assistant", "content": assistant_msg},
        ]
    }


def generate_multi_turn(dealer: dict, vehicles: list, chain: dict) -> dict:
    """Generate a multi-turn conversation following a chain of intents."""
    intents = list(chain["intents"])  # Copy to avoid mutating original

    # â”€â”€ Rebalance: randomly skip Greeting/Farewell (50% chance each) â”€â”€
    # Prevents over-representation in multi-turn chains.
    # Without this, Greeting inflates to ~20% and Farewell to ~11%
    # of all assistant responses, far above targets of 4% and 1.5%.
    if len(intents) > 2:
        if intents[0] == "Greeting" and random.random() < 0.50:
            intents = intents[1:]
        if intents[-1] == "Farewell" and random.random() < 0.50:
            intents = intents[:-1]

    system_prompt = build_system_prompt(dealer, vehicles)

    messages = [{"role": "system", "content": system_prompt}]

    # Track conversation context
    current_vehicle = None
    vehicle_list = []
    context_vehicles = random.sample(vehicles, min(5, len(vehicles)))
    previous_intent = None  # Phase 6: track for context continuity

    for turn_index, intent in enumerate(intents):
        registry = INTENT_REGISTRY.get(intent)
        if not registry:
            continue

        # Select vehicle for this turn
        if registry["requires_vehicle"] or intent in ("FinancingInfo", "TestDriveSchedule"):
            if current_vehicle is None or intent == "VehicleSearch":
                current_vehicle, vehicle_list = select_vehicles_for_intent(intent, context_vehicles)
            if intent == "VehicleComparison" and len(vehicle_list) < 2:
                vehicle_list = random.sample(context_vehicles, min(2, len(context_vehicles)))

        # Pre-generate consistent name/phone for intents that use {name}/{phone}
        user_template = random.choice(registry["user_templates"])
        pre_name = None
        pre_phone = None
        if intent in ("ContactRequest", "CashPurchase") and ("{name}" in user_template or "{phone}" in user_template):
            name_pool = ["Juan PÃ©rez", "MarÃ­a GarcÃ­a", "Carlos RodrÃ­guez",
                         "Ana MartÃ­nez", "Pedro SÃ¡nchez", "Laura DÃ­az",
                         "Gregory Moreno", "Carmen LÃ³pez"]
            if "{name}" in user_template:
                pre_name = random.choice(name_pool)
                user_template = user_template.replace("{name}", pre_name)
            if "{phone}" in user_template:
                pre_phone = f"809-555-{random.randint(1000,9999)}"
                user_template = user_template.replace("{phone}", pre_phone)

        # Generate user message (name/phone already replaced if present)
        user_msg = fill_vehicle_placeholders(
            user_template,
            current_vehicle,
            vehicle_list if len(vehicle_list) >= 2 else None
        )
        user_msg = add_typos_and_slang(user_msg, 0.30)

        # Generate assistant response
        kwargs = {}
        if intent == "VehicleComparison":
            kwargs["vehicles"] = vehicle_list[:2]
        elif intent == "VehicleSearch":
            kwargs["vehicles"] = vehicle_list
            kwargs["bodyType"] = current_vehicle.get("bodyType") if current_vehicle else None
        elif intent in ("VehicleDetails", "VehiclePrice"):
            kwargs["vehicle"] = current_vehicle
        elif intent == "VehicleSpecsQuestion":
            kwargs["vehicle"] = current_vehicle
        elif intent in ("FinancingInfo", "TestDriveSchedule", "WarrantyInfo", "TradeIn",
                        "NegotiatePrice", "InsuranceInfo", "VehicleHistory",
                        "MaintenanceCost", "ColorAvailability"):
            if current_vehicle and random.random() < 0.7:
                kwargs["vehicle"] = current_vehicle
        elif intent == "VehicleAvailability":
            if current_vehicle:
                kwargs["vehicle"] = current_vehicle
        elif intent == "ContactRequest":
            # Only use name/phone if user explicitly provided them in the message
            if pre_name:
                kwargs["name"] = pre_name
            if pre_phone:
                kwargs["phone"] = pre_phone
        elif intent == "CashPurchase":
            if current_vehicle and random.random() < 0.7:
                kwargs["vehicle"] = current_vehicle
            # Only use name/phone if user explicitly provided them in the message
            if pre_name:
                kwargs["name"] = pre_name
            if pre_phone:
                kwargs["phone"] = pre_phone

        response = registry["response_fn"](dealer, **kwargs)
        assistant_msg = json.dumps(response, ensure_ascii=False)
        # Phase 5: emoji reduction
        assistant_msg = apply_emoji_reduction(assistant_msg)
        # Phase 6: inject context continuity phrases for turn 2+
        assistant_msg = inject_context_continuity(
            assistant_msg,
            turn_index=turn_index,
            previous_intent=previous_intent,
            current_vehicle=current_vehicle,
        )

        messages.append({"role": "user", "content": user_msg})
        messages.append({"role": "assistant", "content": assistant_msg})

        previous_intent = intent  # Track for next turn's continuity

    return {"messages": messages}


def generate_dataset(count: int, vehicles: list, dealers: list, seed: int = None) -> list:
    """Generate the full dataset."""
    if seed is not None:
        random.seed(seed)

    dataset = []

    # Calculate counts for each conversation type
    single_count = int(count * CONV_TYPE_DISTRIBUTION["single_turn"])
    short_count = int(count * CONV_TYPE_DISTRIBUTION["short_multi_turn"])
    long_count = count - single_count - short_count

    print(f"\nğŸ“Š DistribuciÃ³n de conversaciones:")
    print(f"   Single-turn: {single_count}")
    print(f"   Short multi-turn (2-4): {short_count}")
    print(f"   Long multi-turn (5-8): {long_count}")
    print()

    # 1. Generate single-turn conversations
    print("ğŸ”„ Generando conversaciones single-turn...")
    intent_pool = []
    for intent, pct in INTENT_DISTRIBUTION.items():
        intent_count = max(1, int(single_count * pct / sum(INTENT_DISTRIBUTION.values())))
        intent_pool.extend([intent] * intent_count)

    random.shuffle(intent_pool)
    for intent in tqdm(intent_pool[:single_count], desc="Single-turn"):
        dealer = random.choice(dealers)
        conv = generate_single_turn(dealer, vehicles, intent)
        if conv:
            dataset.append(conv)

    # 2. Generate short multi-turn conversations (2-4 turns)
    print("\nğŸ”„ Generando conversaciones multi-turn cortas...")
    short_chains = [c for c in MULTI_TURN_CHAINS if 2 <= len(c["intents"]) <= 4]
    if not short_chains:
        short_chains = MULTI_TURN_CHAINS

    for _ in tqdm(range(short_count), desc="Short multi-turn"):
        chain = random.choices(short_chains, weights=[c["weight"] for c in short_chains])[0]
        dealer = random.choice(dealers)
        # Trim to 2-4 intents
        trimmed = deepcopy(chain)
        max_turns = random.randint(2, 4)
        trimmed["intents"] = trimmed["intents"][:max_turns]
        conv = generate_multi_turn(dealer, vehicles, trimmed)
        if conv:
            dataset.append(conv)

    # 3. Generate long multi-turn conversations (5-8 turns)
    print("\nğŸ”„ Generando conversaciones multi-turn largas...")
    long_chains = [c for c in MULTI_TURN_CHAINS if len(c["intents"]) >= 4]
    if not long_chains:
        long_chains = MULTI_TURN_CHAINS

    for _ in tqdm(range(long_count), desc="Long multi-turn"):
        chain = random.choices(long_chains, weights=[c["weight"] for c in long_chains])[0]
        dealer = random.choice(dealers)
        conv = generate_multi_turn(dealer, vehicles, chain)
        if conv:
            dataset.append(conv)

    # â”€â”€ 4. Rebalancing: ensure minimum representation per intent â”€â”€
    # After generation, some intents are under-represented because the
    # multi-turn chain definitions don't include them frequently enough.
    # This "floor" mechanism generates additional single-turn examples
    # for any intent that falls below MIN_INTENT_EXAMPLES.
    MIN_INTENT_EXAMPLES = 50

    intent_counts = Counter()
    for conv in dataset:
        for msg in conv["messages"]:
            if msg["role"] == "assistant":
                try:
                    data = json.loads(msg["content"])
                    intent_counts[data.get("intent", "")] += 1
                except (json.JSONDecodeError, TypeError):
                    pass

    under_represented = {}
    for intent in INTENT_DISTRIBUTION:
        current = intent_counts.get(intent, 0)
        if current < MIN_INTENT_EXAMPLES:
            under_represented[intent] = MIN_INTENT_EXAMPLES - current

    if under_represented:
        print(f"\nâš ï¸  Rebalanceando {len(under_represented)} intents sub-representados "
              f"(piso mÃ­nimo: {MIN_INTENT_EXAMPLES} ejemplos):")
        total_added = 0
        for intent, deficit in sorted(under_represented.items(), key=lambda x: -x[1]):
            added = 0
            for _ in range(deficit):
                dealer = random.choice(dealers)
                conv = generate_single_turn(dealer, vehicles, intent)
                if conv:
                    dataset.append(conv)
                    added += 1
            total_added += added
            print(f"   +{added:3d} {intent} (tenÃ­a {intent_counts.get(intent, 0)})")
        print(f"   â”€â”€ Total agregados: +{total_added} conversaciones single-turn")

    random.shuffle(dataset)
    return dataset


# ============================================================
# SPLIT & SAVE
# ============================================================

def split_dataset(dataset: list, train_pct: float = 0.8, eval_pct: float = 0.1):
    """Split dataset into train/eval/test."""
    n = len(dataset)
    train_end = int(n * train_pct)
    eval_end = train_end + int(n * eval_pct)

    return {
        "train": dataset[:train_end],
        "eval": dataset[train_end:eval_end],
        "test": dataset[eval_end:],
    }


def save_jsonl(data: list, path: Path):
    """Save data as JSONL file."""
    with jsonlines.open(path, mode="w") as writer:
        for item in data:
            writer.write(item)


def compute_stats(dataset: list) -> dict:
    """Compute statistics about the generated dataset."""
    stats = {
        "total_conversations": len(dataset),
        "generated_at": datetime.now().isoformat(),
        "intent_distribution": {},
        "turns_distribution": {},
        "avg_turns": 0,
        "total_messages": 0,
        "dealers_used": set(),
    }

    total_turns = 0
    for conv in dataset:
        messages = conv["messages"]
        # Count user/assistant pairs (turns)
        turns = sum(1 for m in messages if m["role"] == "user")
        total_turns += turns
        stats["total_messages"] += len(messages)

        # Count turns distribution
        turn_bucket = f"{turns}_turns"
        stats["turns_distribution"][turn_bucket] = stats["turns_distribution"].get(turn_bucket, 0) + 1

        # Count intents
        for msg in messages:
            if msg["role"] == "assistant":
                try:
                    resp = json.loads(msg["content"])
                    intent = resp.get("intent", "Unknown")
                    stats["intent_distribution"][intent] = stats["intent_distribution"].get(intent, 0) + 1
                except json.JSONDecodeError:
                    pass

    stats["avg_turns"] = round(total_turns / len(dataset), 2) if dataset else 0
    stats["dealers_used"] = None  # Remove set for JSON serialization

    # Sort intent distribution
    stats["intent_distribution"] = dict(
        sorted(stats["intent_distribution"].items(), key=lambda x: x[1], reverse=True)
    )

    return stats


# ============================================================
# MAIN
# ============================================================

def main():
    parser = argparse.ArgumentParser(
        description="OKLA Chatbot LLM â€” Generador de Dataset SintÃ©tico"
    )
    parser.add_argument(
        "--count", type=int, default=3000,
        help="NÃºmero de conversaciones a generar (default: 3000)"
    )
    parser.add_argument(
        "--output", type=str, default="output",
        help="Directorio de salida (default: output/)"
    )
    parser.add_argument(
        "--seed", type=int, default=42,
        help="Seed para reproducibilidad (default: 42)"
    )
    parser.add_argument(
        "--train-split", type=float, default=0.8,
        help="Porcentaje para train split (default: 0.8)"
    )
    parser.add_argument(
        "--eval-split", type=float, default=0.1,
        help="Porcentaje para eval split (default: 0.1)"
    )
    args = parser.parse_args()

    print("=" * 60)
    print("ğŸ¤– OKLA Chatbot LLM â€” Generador de Dataset SintÃ©tico")
    print("=" * 60)
    print(f"\nğŸ“‹ ConfiguraciÃ³n:")
    print(f"   Conversaciones: {args.count}")
    print(f"   Output: {args.output}/")
    print(f"   Seed: {args.seed}")
    print(f"   Split: {args.train_split:.0%} train / {args.eval_split:.0%} eval / "
          f"{1 - args.train_split - args.eval_split:.0%} test")

    # Load seed data
    print(f"\nğŸ“‚ Cargando datos seed...")
    vehicles = load_json(VEHICLES_FILE)
    dealers = load_json(DEALERS_FILE)
    print(f"   âœ… {len(vehicles)} vehÃ­culos")
    print(f"   âœ… {len(dealers)} dealers")

    # Generate
    print(f"\nğŸš€ Generando {args.count} conversaciones...\n")
    dataset = generate_dataset(args.count, vehicles, dealers, args.seed)
    print(f"\nâœ… Generadas {len(dataset)} conversaciones")

    # Split
    splits = split_dataset(dataset, args.train_split, args.eval_split)
    print(f"\nğŸ“Š Splits:")
    for name, data in splits.items():
        print(f"   {name}: {len(data)} conversaciones")

    # Save
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)

    for name, data in splits.items():
        path = output_dir / f"okla_{name}.jsonl"
        save_jsonl(data, path)
        print(f"   ğŸ’¾ Guardado: {path}")

    # R8: Generate SHA256 hash of dataset for traceability / lineage
    import hashlib
    print(f"\nğŸ” Generando hashes de dataset...")
    dataset_hashes = {}
    for name in splits:
        path = output_dir / f"okla_{name}.jsonl"
        sha256 = hashlib.sha256()
        with open(path, "rb") as f:
            for chunk in iter(lambda: f.read(8192), b""):
                sha256.update(chunk)
        dataset_hashes[f"okla_{name}.jsonl"] = sha256.hexdigest()
        print(f"   ğŸ“ {name}: {sha256.hexdigest()[:16]}...")

    # Save dataset manifest with hashes
    manifest = {
        "generated_at": datetime.now().isoformat(),
        "generator": "generate_dataset.py",
        "generator_version": "2.0.0",
        "seed": args.seed,
        "total_conversations": len(dataset),
        "splits": {name: len(data) for name, data in splits.items()},
        "file_hashes_sha256": dataset_hashes,
        "intent_count": len(set(
            conv.get("intent", "unknown")
            for conv in dataset
        )),
        "python_version": sys.version,
        "command": " ".join(sys.argv),
    }
    manifest_path = output_dir / "dataset_manifest.json"
    with open(manifest_path, "w", encoding="utf-8") as f:
        json.dump(manifest, f, indent=2, ensure_ascii=False)
    print(f"   ğŸ“‹ Manifest: {manifest_path}")

    # Stats
    stats = compute_stats(dataset)
    stats_path = output_dir / "stats.json"
    with open(stats_path, "w", encoding="utf-8") as f:
        json.dump(stats, f, indent=2, ensure_ascii=False)
    print(f"   ğŸ“ˆ Stats: {stats_path}")

    # Summary
    print(f"\n{'=' * 60}")
    print(f"ğŸ“Š RESUMEN")
    print(f"{'=' * 60}")
    print(f"Total conversaciones: {stats['total_conversations']}")
    print(f"Promedio de turnos: {stats['avg_turns']}")
    print(f"Total mensajes: {stats['total_messages']}")
    print(f"\nğŸ·ï¸ Top 10 Intents:")
    for intent, count in list(stats["intent_distribution"].items())[:10]:
        pct = count / sum(stats["intent_distribution"].values()) * 100
        print(f"   {intent:25s} {count:5d} ({pct:.1f}%)")

    print(f"\nğŸ“ Archivos generados en: {output_dir.absolute()}")
    print(f"{'=' * 60}")
    print("âœ… Â¡Dataset generado exitosamente!")
    print("   PrÃ³ximo paso: python validate_dataset.py output/okla_train.jsonl")


if __name__ == "__main__":
    main()
